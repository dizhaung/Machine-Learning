# AutoEncoder

之前的机器学习算法都需要人工指定特征的具体形式, 这个过程被称为特征处理. 这样做的缺点是如果选取的特征不能较好
的体现原始数据, 则最终的结果不会很好. 而深度学习很好的解决了这样的问题.

深度学习是指利用神经网络的技术能够自动提取出数据中的特征, 这个过程被称为特征学习.

AutoEncoder是最基本的特征学习方式, 对于一些无标注的数据, AutoEncoder通过重构输入数据以达到自我学习的目的.

## 前言

典型的三层结构神经网络模型, BP神经网络.[详情](../Part1-Classification/Chapter6-Back-Propagation.md)

### 逐层训练

问题的提出: 增加更多的隐含层数(对样本通过线性变换和非线性变换), 实现对样本的更高级抽象, 但是随着隐含层数的追加, 
同时增加了训练的难度, 也会出现诸如梯度弥散等现象.
- 在逐层训练中, 每次训练相邻的两层, 前一层输出作为下一层的输入, 从而构建多层的神经网络.
    - 逐层训练使得深度网络的训练成为可能?
        - 一个直观的解释: 预训练好的网络在一定程度上拟合了训练数据的结构, 这使得整个网络的初始值是在一个合适的
        状态, 便于有监督阶段加快迭代收敛
    - 为什么不直接训练更多层的网络?
        - 直接训练一个深层的自编码器, 其实本质上就是在做深度网络训练, 由于梯度扩散等问题, 这样的网络往往根本无法训练.
- 每两层之间的的变换都是"线性变换" + "非线性激活"
    - 编码过程: 隐含层的输出H = σ(W<sub>1</sub>X+b<sub>1</sub>), σ是一个非线性映射, 如Sigmoid函数.
    - 解码过程: 输出层的输出Z = σ(W<sub>2</sub>H+b<sub>2</sub>), Z可以看成是利用特征H对原始数据X的预测.

自编码器AutoEncoder是一种用于训练相邻两层网络模型的一种方法.它是典型的无监督学习算法.

损失函数可以使用:
- 均方差误差:
<br><center>![](../MularGif/Part5-DeepLearning/Chpater17Gif/Loos%20Function%201.gif)</center></br>
- 交叉熵误差
<br><center>![](../MularGif/Part5-DeepLearning/Chpater17Gif/Loos%20Function%202.gif)</center></br>

## 降噪自编码器Denoising AutoEncoder

原理: 自编码器对输入数据在隐含层进行编码(非线性映射), 然后隐含层的输出作为输出层的输入并进行解码, 并期望
结果能够尽可能还原样本.但是, 在样本中难免会有噪音的出现, 因此我们的编码器还需要有降噪功能.

在样本中加入噪音(防止过拟合, 提升鲁棒性): 使用较多的noise主要是mask noise, 即原始数据中部分数据缺失, 这是有着实际意义的, 比如图像部分
像素被遮挡, 文本因记录原因漏掉了一些单词等等.

## 利用Denoising AutoEncoder构建深度网络

主要有两个过程
- 无监督的逐层训练, 即依次训练多个降噪自编码器Denoising AutoEncoder
    - 从最开始的输入层依次经过多个隐含层至最后的输出层, 使用前一层的输出作为输入经过激活函数处理, 逐层训练, 
    从而得到多个降噪自编码器的编码过程, 这样的逐层训练过程称为预训练.
- 有监督的微调, 即将训练好的多个降噪自编码器的编码Encoder层组合起来, 利用样本标签对训练好的降噪自编码器的编码
的编码Encoder层的参数微调
    - 将训练好的降噪自编码器堆叠在一起, 并在最后一层加入有监督的分类(如多分类的Softmax Regression或者
    二分类的Logistic Regression).
    
具体步骤:
- 初始化各层网络的权重W和偏置b
- 利用损失函数, 调整各层网络的权重和偏置. 在堆叠降噪自编码器的初始化过程中, 充分利用预训练过程的结果, 将预训练过程中
得到的网络权重和偏置作为堆叠降噪自编码神经网络的初始值, 并利用整个网络的损失函数, 对这些初始值进行调整, 对权重
和偏置调整的过程称为有监督的微调.

## 杂谈

- [自编码器](https://www.zhihu.com/question/41490383)
- [交叉熵代价函数](https://blog.csdn.net/lanchunhui/article/details/50970625)
- [PCA](https://www.cnblogs.com/zy230530/p/7074215.html)
- [自编码器的作用](https://baijiahao.baidu.com/s?id=1593919387670320658&wfr=spider&for=pc)