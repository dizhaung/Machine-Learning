# Python 机器学习算法总结

## Logistic Regression

属于线性的分类模型, 主要处理二分类问题, 使用阈值函数sigmoid(带有均一化功能), 求导转换为凸优化或者非凸优化问题. 
由于导函数的形式为f(x)[1-f(x)], 因此引入伯努利分布的似然函数(Log似然函数求解似然函数的最大值问题). 
并通过梯度下降的方法解出凸优化问题的解(步长影响收敛速度及震荡问题).

## Softmax Regression

是Logistic Regression在多分类问题上的扩展, 都是利用假设函数估计样本所属类别的概率, 利用损失函数及梯度下降求得最优解.

## Factorization Machine

- 主要针对特征之间不独立的情况
- 基于矩阵分解的思想, 用来处理非线性可分的问题.一般用来处理回归、二分类、排序问题.由于数据稀疏性的问题, 引入基于
矩阵分解思想的辅助向量对模型求解. 对于高度稀疏的数据场景具有较好的效果.

## Support Vector Machine

- 适用于二分类问题
- SVM它本质上即是一个分类方法,用w^T+b定义分类函数,于是求w、b,为寻最大间隔,引出1/2||w||^2,继而引入拉格朗日因子,
化为对拉格朗日乘子a的求解（求解过程中会涉及到一系列最优化或凸二次规划等问题）,如此,求w.b与求a等价,
而a的求解可以用一种快速学习算法SMO,至于核函数,是为处理非线性情况,若直接映射到高维计算恐维度爆炸,
故在低维计算,等效高维表现.

## 杂谈
- [模型选择](MularGif/module%20choice.jpg)